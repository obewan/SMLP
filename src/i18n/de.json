{
    "-i,--import_network": "Importieren Sie ein Netzwerkmodell anstelle eines neuen. Dies muss ein gültiger Modell-Dateipfad sein, speziell eine von SMLP generierte Datei. Wenn diese Option verwendet wird, müssen die Schichtparameter nicht angegeben werden, da sie im Modell enthalten sind.",
    "-e,--export_network":  "Exportieren Sie das Netzwerkmodell nach dem Training. Dies muss ein gültiger Dateipfad sein. Das exportierte Modell kann später importiert werden, wodurch ein erneutes Training entfällt.",
    "-f,--file_input":  "Geben Sie die für das Training und Testing verwendete Daten-Datei an.",
    "-s,--input_size": "Die Anzahl der Eingangsneuronen",
    "-o,--output_size": "Die Anzahl der Ausgangsneuronen",
    "-d,--hidden_size": "Die Anzahl der versteckten Neuronen pro versteckter Schicht",
    "-c,--hiddens_count": "Die Anzahl der versteckten Schichten",
    "-p,--epochs": "Die Anzahl der Epochen des Trainings",
    "-l,--learning_rate": "Die Lernrate des Netzwerktrainings",
    "-t,--output_ends": "Gibt an, dass die Ausgangsspalten des Datensatzes am Ende des Datensatzes liegen.\nStandardmäßig sucht smlp in den ersten Spalten",
    "-r,--training_ratio": "Das Trainingsverhältnis der Datei zum Wechseln zwischen Daten für das Training und Daten für das Testen sollte etwa 0,7 betragen",
    "-R,--training_ratio_line": "Die Zeilennummer des Trainingsverhältnisses der Datei zum Wechseln zwischen Daten für das Training und Daten für den Test, sollte sich bei 70% der Datei befinden",
    "-m,--mode": "Wählen Sie den Laufmodus aus:\n  - Predictive: Dieser Modus verwendet eine Eingabedatei, um die Ausgänge vorherzusagen.\n    Wenn die Eingabedatei Ausgangsspalten enthält, werden die vorhergesagten CSV-Ausgänge sie ersetzen, ohne die ursprüngliche Eingabedatei zu ändern.\n    Bitte beachten Sie die Parameter (input_size, output_size, output_ends). Wenn die Eingabedatei keine Ausgangsspalten enthält, achten Sie genau auf den input_size-Parameter.\n    Dieser Modus erfordert ein importiertes und trainiertes Netzwerk (stellen Sie sicher, dass das Modell gute Testergebnisse hat).\n  - TestOnly: Testen Sie ein importiertes Netzwerk ohne Training.\n  - TrainOnly: Trainieren Sie das Netzwerk ohne Testen.\n  - TrainThenTest: Trainieren und dann testen Sie das Netzwerk (Standard).\n  - TrainTestMonitored: Trainieren und testen Sie bei jeder Epoche, während Sie den Fortschritt eines Ausgangsneurons überwachen. Beachten Sie, dass dies langsamer ist und mehr Speicher benötigt.",
    "-n,--predictive_mode": "Wenn Sie den Vorhersagemodus verwenden, wählen Sie den Ausgaberendermodus aus:\n  - CSV: Dies wird die Ausgabe(n) am Ende oder am Anfang der Eingabezeile rendern, abhängig von Ihrer output_ends-Option (Standard).\n  - NumberAndRaw: Dies zeigt sowohl die vorhergesagten Ausgabe(n) Zahlen als auch ihre Rohwerte.\n  - NumberOnly: Dies zeigt nur die vorhergesagte Ausgabezahl.\n  - RawOnly: Dies zeigt nur die Rohwerte der Ausgabe(n).",
    "-y,--output_index_to_monitor": "Geben Sie den Index des Ausgangsneurons an, das während eines TrainTestMonitored-Modus überwacht werden soll. Wenn index = 0, gibt es keine Fortschrittsüberwachung. Standard ist 1, das erste Neuronenoutput.",
    "-a,--hidden_activation_function": "Wählen Sie die Aktivierungsfunktion der versteckten Neuronen aus:\n  - ELU: Exponential Linear Units, erfordert einen hidden_activation_alpha-Parameter.\n  - LReLU: Leaky ReLU.\n  - PReLU: Parametric ReLU, erfordert einen hidden_activation_alpha-Parameter.\n  - ReLU: Rectified Linear Unit.\n  - Sigmoid (Standard).\n  - Tanh: Hyperbolische Tangente",
    "-b,--output_activation_function": "Wählen Sie die Aktivierungsfunktion der Ausgangsneuronen aus:\n  - ELU: Exponential Linear Units, erfordert einen output_activation_alpha-Parameter.\n  - LReLU: Leaky ReLU.\n  - PReLU: Parametric ReLU, erfordert einen output_activation_alpha-Parameter.\n  - ReLU: Rectified Linear Unit.\n  - Sigmoid (Standard).\n  - Tanh: Hyperbolische Tangente",
    "-k,--hidden_activation_alpha": "Der Alpha-Parameterwert für ELU- und PReLU-Aktivierungsfunktionen in versteckten Schichten",
    "-q,--output_activation_alpha": "Der Alpha-Parameterwert für ELU- und PReLU-Aktivierungsfunktionen in der Ausgangsschicht",
    "-x,--disable_stdin": "Deaktivieren Sie die stdin-Eingabe wie Befehlsrohre (pipes) und interaktives Testen",
    "-v,--version": "Aktuelle Version anzeigen",
    "-w,--verbose": "Ausführliche Logs",

    "UnknownKey": "Unbekannter Schlüssel",
    "FailedToOpenFile": "Datei konnte nicht geöffnet werden",
    "InvalidJsonFile": "Ungültige JSON-Datei",
    "JsonParsingError": "Fehler beim Parsen von JSON",
    "InvalidTotalInput": "Ungültige Anzahl von Eingabewerten"
}
